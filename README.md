# DirHunter AI â€” Advanced Filtering & Reporting README

## ğŸ“¦ Overview
DirHunter AI is an advanced Python-based fuzzing and filtering pipeline designed to:
âœ… Discover hidden endpoints using FFUF  
âœ… Filter out noise and false positives using heuristics, hashes, and content patterns  
âœ… Classify high-signal findings using GPT-4 Vision  
âœ… Log all actions with detailed skip/keep reasons and timestamps  
âœ… Generate HTML reports and Slack alerts for actionable results

---

## ğŸ— File Structure
```
dirhunter_ai/
â”œâ”€â”€ config.py
â”œâ”€â”€ domain.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ai_analyzer.py
â”‚   â”œâ”€â”€ db_handler.py
â”‚   â”œâ”€â”€ filters.py
â”‚   â”œâ”€â”€ reporter.py
â”‚   â”œâ”€â”€ scanner.py
â”‚   â”œâ”€â”€ screenshot.py
â”‚   â”œâ”€â”€ slack_alert.py
â””â”€â”€ db/
    â””â”€â”€ endpoint_hashes.sqlite
â””â”€â”€ logs/
    â”œâ”€â”€ skipped_YYYYMMDD_HHMM.txt
    â”œâ”€â”€ kept_YYYYMMDD_HHMM.txt
    â””â”€â”€ summary_YYYYMMDD_HHMM.txt
```

---

## ğŸš€ How to Run
1ï¸âƒ£ Prepare your `domain.txt` with one domain per line.

2ï¸âƒ£ Run the main script:
```bash
python3 main.py
```

### Optional Flags
- `--ignore-hash` â†’ Forces reprocessing of all endpoints (ignores DB hash cache)
- `--reset-db` â†’ Clears the entire hash database (`endpoint_hashes.sqlite`)
- `--screenshot-workers <N>` â†’ Sets number of parallel screenshot threads (default: 5)

Examples:
```bash
python3 main.py --ignore-hash
python3 main.py --reset-db
python3 main.py --screenshot-workers 10
```

---

## âš™ Features
âœ… FFUF scanning with:
- `-r` redirects
- `-fc 404,429` filtered codes
- configurable wordlists/extensions

âœ… Advanced filtering:
- Heuristic: status + length + sensitive keywords
- Pattern skip: e.g., `/api/`, `/healthz`, `/status`
- Soft-404 detection via parallel curl
- Response body SHA-1 clustering
- Persistent DB for tracking endpoint changes

âœ… Logging Enhancements:
- Skip/keep reasons logged with `[length-filter]`, `[curl-soft404]`, `[pattern-skip]`, `[hash-unchanged]`
- Timestamped logs for clear tracking
- Per-domain summary stats

âœ… AI Classification:
- Uses GPT-4 Vision to assign one of 14 categories (Admin Panel, Login Panel, Secrets, etc.)
- Helps prioritize only the most critical findings

âœ… Reporting:
- HTML grouped reports by tag
- Slack notifications for high-severity results

---

## ğŸ“‚ Logs Explained
```
logs/
â”œâ”€â”€ skipped_YYYYMMDD_HHMM.txt   # All skipped endpoints + reason
â”œâ”€â”€ kept_YYYYMMDD_HHMM.txt      # All kept endpoints after filtering
â””â”€â”€ summary_YYYYMMDD_HHMM.txt   # Summary stats per domain
```

## ğŸ“¦ Database
- SQLite DB stores seen URLs + content hashes
- Skips unchanged endpoints on reruns (unless `--ignore-hash` is set)
- Reset with `--reset-db`

---

## ğŸ”§ Requirements
- Python 3.8+
- FFUF installed and available in `$PATH`
- OpenAI API key set in environment (for Vision)
- curl installed
- ChromeDriver + Selenium for screenshots

---

## âœ¨ Roadmap
âœ… Per-path heuristic skips  
âœ… Soft-404 hash clustering  
âœ… Parallel curl for speed  
âœ… Persistent hash DB  
âœ… Command-line flags for reset/force/thread control  
âœ… Detailed logs + summaries  
âœ… High-signal AI tagging  

Let me know if you want a Dockerfile, Makefile, or CI integration script next!
